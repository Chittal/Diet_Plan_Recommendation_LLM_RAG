{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RAG System Using Llama2 With Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otbFMCmWAeV2",
        "outputId": "7d939d00-5587-4d0e-e66b-5dbe305b35d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "replace data/data/diet_plan/Asthama/000360398.pdf? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "# !unzip data.zip -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2xBuA9nlSmu",
        "outputId": "8027507f-ef55-42ab-d5e0-3f106a258d39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pypdf\n",
            "  Using cached pypdf-5.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Using cached pypdf-5.0.1-py3-none-any.whl (294 kB)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-5.0.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting sentence_transformersNote: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sentence_transformers) (4.45.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sentence_transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sentence_transformers) (2.5.0)\n",
            "Collecting scikit-learn (from sentence_transformers)\n",
            "  Using cached scikit_learn-1.5.2-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
            "Collecting scipy (from sentence_transformers)\n",
            "  Using cached scipy-1.14.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sentence_transformers) (0.26.1)\n",
            "Collecting Pillow (from sentence_transformers)\n",
            "  Using cached pillow-11.0.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.1)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->sentence_transformers)\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
            "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n",
            "Downloading sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n",
            "Using cached pillow-11.0.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
            "Using cached scikit_learn-1.5.2-cp311-cp311-win_amd64.whl (11.0 MB)\n",
            "Using cached scipy-1.14.1-cp311-cp311-win_amd64.whl (44.8 MB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, Pillow, joblib, scikit-learn, sentence_transformers\n",
            "Successfully installed Pillow-11.0.0 joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 sentence_transformers-3.2.1 threadpoolctl-3.5.0\n",
            "Collecting llama_index\n",
            "  Using cached llama_index-0.11.19-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-agent-openai<0.4.0,>=0.3.4 (from llama_index)\n",
            "  Using cached llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-cli<0.4.0,>=0.3.1 (from llama_index)\n",
            "  Using cached llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.12.0,>=0.11.19 (from llama_index)\n",
            "  Using cached llama_index_core-0.11.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.4 (from llama_index)\n",
            "  Using cached llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama_index)\n",
            "  Using cached llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama_index)\n",
            "  Using cached llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.3.0,>=0.2.10 (from llama_index)\n",
            "  Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama_index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.2.3-py3-none-any.whl.metadata (729 bytes)\n",
            "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama_index)\n",
            "  Using cached llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama_index)\n",
            "  Using cached llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama_index)\n",
            "  Using cached llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama_index)\n",
            "  Using cached llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting nltk>3.8.1 (from llama_index)\n",
            "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.4.0,>=0.3.4->llama_index)\n",
            "  Downloading openai-1.52.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.19->llama_index) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (3.10.10)\n",
            "Collecting dataclasses-json (from llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (2024.10.0)\n",
            "Requirement already satisfied: httpx in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (3.4.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (11.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Using cached tiktoken-0.8.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.19->llama_index) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting wrapt (from llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Using cached wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama_index)\n",
            "  Using cached llama_cloud-0.1.4-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting pandas (from llama-index-legacy<0.10.0,>=0.9.48->llama_index)\n",
            "  Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
            "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index)\n",
            "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index)\n",
            "  Using cached pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index)\n",
            "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama_index)\n",
            "  Downloading llama_parse-0.5.11-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting click (from nltk>3.8.1->llama_index)\n",
            "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: joblib in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from nltk>3.8.1->llama_index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from nltk>3.8.1->llama_index) (2024.9.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.16.0)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama_index)\n",
            "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: anyio in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (4.6.2.post1)\n",
            "Requirement already satisfied: certifi in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.0.6)\n",
            "Requirement already satisfied: idna in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (3.10)\n",
            "Requirement already satisfied: sniffio in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.19->llama_index) (0.14.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from click->nltk>3.8.1->llama_index) (0.4.6)\n",
            "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama_index)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama_index)\n",
            "  Using cached jiter-0.6.1-cp311-none-win_amd64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.19->llama_index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.19->llama_index) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.19->llama_index) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.19->llama_index) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.19->llama_index) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.12.0,>=0.11.19->llama_index)\n",
            "  Using cached marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index)\n",
            "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index)\n",
            "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.19->llama_index) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.19->llama_index) (0.2.0)\n",
            "Using cached llama_index-0.11.19-py3-none-any.whl (6.8 kB)\n",
            "Using cached llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\n",
            "Using cached llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\n",
            "Using cached llama_index_core-0.11.19-py3-none-any.whl (1.6 MB)\n",
            "Using cached llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\n",
            "Using cached llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl (10 kB)\n",
            "Using cached llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n",
            "Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.2.3-py3-none-any.whl (5.9 kB)\n",
            "Using cached llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
            "Using cached llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
            "Using cached llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\n",
            "Using cached llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\n",
            "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
            "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Using cached llama_cloud-0.1.4-py3-none-any.whl (176 kB)\n",
            "Downloading llama_parse-0.5.11-py3-none-any.whl (13 kB)\n",
            "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Downloading openai-1.52.1-py3-none-any.whl (386 kB)\n",
            "Using cached pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Using cached tiktoken-0.8.0-cp311-cp311-win_amd64.whl (884 kB)\n",
            "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Using cached wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
            "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached jiter-0.6.1-cp311-none-win_amd64.whl (201 kB)\n",
            "Using cached marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
            "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
            "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "Installing collected packages: striprtf, pytz, dirtyjson, wrapt, tzdata, tenacity, soupsieve, pypdf, mypy-extensions, marshmallow, jiter, distro, click, typing-inspect, tiktoken, pandas, nltk, deprecated, beautifulsoup4, openai, llama-cloud, dataclasses-json, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama_index\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: pypdf\n",
            "    Found existing installation: pypdf 5.0.1\n",
            "    Uninstalling pypdf-5.0.1:\n",
            "      Successfully uninstalled pypdf-5.0.1\n",
            "Successfully installed beautifulsoup4-4.12.3 click-8.1.7 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 jiter-0.6.1 llama-cloud-0.1.4 llama-index-agent-openai-0.3.4 llama-index-cli-0.3.1 llama-index-core-0.11.19 llama-index-embeddings-openai-0.2.5 llama-index-indices-managed-llama-cloud-0.4.0 llama-index-legacy-0.9.48.post3 llama-index-llms-openai-0.2.16 llama-index-multi-modal-llms-openai-0.2.3 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.2 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.11 llama_index-0.11.19 marshmallow-3.23.0 mypy-extensions-1.0.0 nltk-3.9.1 openai-1.52.1 pandas-2.2.3 pypdf-4.3.1 pytz-2024.2 soupsieve-2.6 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.8.0 typing-inspect-0.9.0 tzdata-2024.2 wrapt-1.16.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting langchain-communityNote: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "  Using cached langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langchain-community) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.4 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langchain-community) (0.3.4)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langchain-community) (0.3.12)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langchain-community) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Using cached pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.16.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langchain<0.4.0,>=0.3.4->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langchain<0.4.0,>=0.3.4->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.6.2.post1)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
            "Requirement already satisfied: sniffio in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain-community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
            "Using cached langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
            "Using cached pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
            "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, pydantic-settings, langchain-community\n",
            "Successfully installed langchain-community-0.3.3 pydantic-settings-2.6.0 python-dotenv-1.0.1\n",
            "Collecting llama-index-llms-huggingface\n",
            "  Downloading llama_index_llms_huggingface-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting huggingface-hub<0.24.0,>=0.23.0 (from llama-index-llms-huggingface)\n",
            "  Using cached huggingface_hub-0.23.5-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-llms-huggingface) (0.11.19)\n",
            "Collecting text-generation<0.8.0,>=0.7.0 (from llama-index-llms-huggingface)\n",
            "  Using cached text_generation-0.7.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-llms-huggingface) (2.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.45.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.12.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.0.8)\n",
            "Requirement already satisfied: httpx in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (11.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.8.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.9.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.16.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sympy==1.13.1->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.20.1)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (1.0.1)\n",
            "Requirement already satisfied: psutil in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (6.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.16.0)\n",
            "Requirement already satisfied: click in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.4.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.1.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (0.4.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.23.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (4.6.2.post1)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.0.6)\n",
            "Requirement already satisfied: sniffio in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.0.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.2.0)\n",
            "Downloading llama_index_llms_huggingface-0.3.5-py3-none-any.whl (11 kB)\n",
            "Using cached huggingface_hub-0.23.5-py3-none-any.whl (402 kB)\n",
            "Using cached text_generation-0.7.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: huggingface-hub, text-generation, llama-index-llms-huggingface\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.26.1\n",
            "    Uninstalling huggingface-hub-0.26.1:\n",
            "      Successfully uninstalled huggingface-hub-0.26.1\n",
            "Successfully installed huggingface-hub-0.23.5 llama-index-llms-huggingface-0.3.5 text-generation-0.7.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting llama-index-embeddings-langchain\n",
            "  Downloading llama_index_embeddings_langchain-0.2.1-py3-none-any.whl.metadata (612 bytes)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-embeddings-langchain) (0.11.19)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2024.10.0)\n",
            "Requirement already satisfied: httpx in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (11.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (0.9.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.16.0)\n",
            "Requirement already satisfied: click in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (3.1.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (0.4.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (3.23.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (4.6.2.post1)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.0.6)\n",
            "Requirement already satisfied: sniffio in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (0.14.0)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (24.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-langchain) (0.2.0)\n",
            "Downloading llama_index_embeddings_langchain-0.2.1-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: llama-index-embeddings-langchain\n",
            "Successfully installed llama-index-embeddings-langchain-0.2.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting chromadbNote: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "  Using cached chromadb-0.5.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb) (2.9.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Using cached chroma_hnswlib-0.7.6-cp311-cp311-win_amd64.whl.metadata (262 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.3-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Using cached posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Using cached onnxruntime-1.19.2-cp311-cp311-win_amd64.whl.metadata (4.7 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Using cached opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb) (0.20.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb) (4.66.5)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting importlib-resources (from chromadb)\n",
            "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting grpcio>=1.58.0 (from chromadb)\n",
            "  Using cached grpcio-1.67.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Using cached bcrypt-4.2.0-cp39-abi3-win_amd64.whl.metadata (9.9 kB)\n",
            "Collecting typer>=0.9.0 (from chromadb)\n",
            "  Using cached typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Using cached kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Using cached mmh3-5.0.1-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb) (3.10.10)\n",
            "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb) (0.27.2)\n",
            "Collecting rich>=10.11.0 (from chromadb)\n",
            "  Downloading rich-13.9.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: packaging>=19.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.41.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.6.2.post1)\n",
            "Requirement already satisfied: certifi in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.6)\n",
            "Requirement already satisfied: idna in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: sniffio in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: requests in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: sympy in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Using cached importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (65.5.0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.23.5)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached httptools-0.6.4-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached watchfiles-0.24.0-cp311-none-win_amd64.whl.metadata (5.0 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached websockets-13.1-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Collecting zipp>=0.5 (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
            "  Using cached zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Using cached chromadb-0.5.15-py3-none-any.whl (607 kB)\n",
            "Using cached chroma_hnswlib-0.7.6-cp311-cp311-win_amd64.whl (151 kB)\n",
            "Using cached bcrypt-4.2.0-cp39-abi3-win_amd64.whl (151 kB)\n",
            "Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.3-py3-none-any.whl (94 kB)\n",
            "Using cached grpcio-1.67.0-cp311-cp311-win_amd64.whl (4.4 MB)\n",
            "Using cached kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "Using cached mmh3-5.0.1-cp311-cp311-win_amd64.whl (39 kB)\n",
            "Using cached onnxruntime-1.19.2-cp311-cp311-win_amd64.whl (11.1 MB)\n",
            "Using cached opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
            "Using cached opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
            "Using cached opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
            "Using cached opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
            "Using cached opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
            "Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
            "Using cached opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
            "Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
            "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Using cached posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n",
            "Downloading rich-13.9.3-py3-none-any.whl (242 kB)\n",
            "Using cached typer-0.12.5-py3-none-any.whl (47 kB)\n",
            "Using cached uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
            "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Using cached durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Using cached google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
            "Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
            "Using cached httptools-0.6.4-cp311-cp311-win_amd64.whl (88 kB)\n",
            "Using cached importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading starlette-0.41.0-py3-none-any.whl (73 kB)\n",
            "Using cached watchfiles-0.24.0-cp311-none-win_amd64.whl (277 kB)\n",
            "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "Using cached websockets-13.1-cp311-cp311-win_amd64.whl (159 kB)\n",
            "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
            "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Using cached zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
            "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: pypika, monotonic, flatbuffers, durationpy, zipp, websockets, websocket-client, shellingham, pyreadline3, pyproject_hooks, pyasn1, protobuf, overrides, opentelemetry-util-http, oauthlib, mmh3, mdurl, importlib-resources, httptools, grpcio, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, humanfriendly, googleapis-common-protos, build, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, google-auth, fastapi, coloredlogs, typer, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.2.post1 cachetools-5.5.0 chroma-hnswlib-0.7.6 chromadb-0.5.15 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.3 flatbuffers-24.3.25 google-auth-2.35.0 googleapis-common-protos-1.65.0 grpcio-1.67.0 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.4.0 importlib-resources-6.4.5 kubernetes-31.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.0.1 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.19.2 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 overrides-7.7.0 posthog-3.7.0 protobuf-4.25.5 pyasn1-0.6.1 pyasn1-modules-0.4.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rich-13.9.3 rsa-4.9 shellingham-1.5.4 starlette-0.41.0 typer-0.12.5 uvicorn-0.32.0 watchfiles-0.24.0 websocket-client-1.8.0 websockets-13.1 zipp-3.20.2\n",
            "Collecting llama-index-vector-stores-chroma\n",
            "  Downloading llama_index_vector_stores_chroma-0.2.1-py3-none-any.whl.metadata (755 bytes)\n",
            "Requirement already satisfied: chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-vector-stores-chroma) (0.5.15)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-vector-stores-chroma) (0.11.19)\n",
            "Requirement already satisfied: build>=1.0.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.9.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.115.3)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.32.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.19.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.27.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.20.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.66.5)\n",
            "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.67.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.2.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.12.5)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (31.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.10.10)\n",
            "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (13.9.3)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (2024.10.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (3.9.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (11.0.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (0.8.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (0.9.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.16.0)\n",
            "Requirement already satisfied: packaging>=19.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.2.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.4.6)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from fastapi>=0.95.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.41.0)\n",
            "Requirement already satisfied: anyio in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.6.2.post1)\n",
            "Requirement already satisfied: certifi in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.0.6)\n",
            "Requirement already satisfied: idna in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.10)\n",
            "Requirement already satisfied: sniffio in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.35.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.2.3)\n",
            "Requirement already satisfied: durationpy>=0.7 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.9)\n",
            "Requirement already satisfied: click in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (2024.9.11)\n",
            "Requirement already satisfied: coloredlogs in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.25.5)\n",
            "Requirement already satisfied: sympy in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (8.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.65.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.27.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.48b0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.48b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (65.5.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (3.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.23.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.0.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (13.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (3.23.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.16.1)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.20.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.1.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-chroma) (0.2.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyreadline3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (3.5.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0->llama-index-vector-stores-chroma) (0.6.1)\n",
            "Downloading llama_index_vector_stores_chroma-0.2.1-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: llama-index-vector-stores-chroma\n",
            "Successfully installed llama-index-vector-stores-chroma-0.2.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting PyMuPDFNote: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "  Downloading PyMuPDF-1.24.12-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: sentence-transformers in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sentence-transformers) (4.45.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sentence-transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chitt\\downloads\\llama2_code\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
            "Downloading PyMuPDF-1.24.12-cp39-abi3-win_amd64.whl (16.0 MB)\n",
            "   ---------------------------------------- 0.0/16.0 MB ? eta -:--:--\n",
            "   --- ------------------------------------ 1.3/16.0 MB 9.6 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 11.0/16.0 MB 32.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  15.7/16.0 MB 35.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  15.7/16.0 MB 35.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 16.0/16.0 MB 17.6 MB/s eta 0:00:00\n",
            "Installing collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.12\n"
          ]
        }
      ],
      "source": [
        "%pip install pypdf\n",
        "%pip install -q transformers einops accelerate langchain bitsandbytes\n",
        "%pip install sentence_transformers\n",
        "%pip install llama_index\n",
        "%pip install -U langchain-community\n",
        "%pip install llama-index-llms-huggingface\n",
        "%pip install llama-index-embeddings-langchain\n",
        "%pip install chromadb\n",
        "%pip install llama-index-vector-stores-chroma\n",
        "%pip install PyMuPDF sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33roSPWLlYEv",
        "outputId": "749c95ca-721c-48c1-c674-9988c1cebb45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Chitt\\Downloads\\LLAMA2_code\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "c:\\Users\\Chitt\\Downloads\\LLAMA2_code\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_id\" in DeployedModel has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Chitt\\Downloads\\LLAMA2_code\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Chitt\\Downloads\\LLAMA2_code\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_kwargs\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Chitt\\Downloads\\LLAMA2_code\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPI has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Chitt\\Downloads\\LLAMA2_code\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in TextGenerationInference has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     c:\\Users\\Chitt\\Downloads\\LLAMA2_code\\.venv\\Lib\\site-\n",
            "[nltk_data]     packages\\llama_index\\legacy\\_static/nltk_cache...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     c:\\Users\\Chitt\\Downloads\\LLAMA2_code\\.venv\\Lib\\site-\n",
            "[nltk_data]     packages\\llama_index\\legacy\\_static/nltk_cache...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "import json\n",
        "\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.core.prompts.prompts import SimpleInputPrompt\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index.core import ServiceContext\n",
        "from llama_index.legacy.embeddings.langchain import LangchainEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core import Settings\n",
        "\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "from llama_index.core import StorageContext\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from chromadb import PersistentClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('disease_description.json', 'r') as f:\n",
        "    disease_description = json.load(f)  # Load the JSON data into a Python dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gTy1gzVHKfB1"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(file_path):\n",
        "  with fitz.open(file_path) as pdf_document:\n",
        "      text = \"\"\n",
        "      for page in pdf_document:\n",
        "          text += page.get_text()\n",
        "      return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hYcjW_iAvonM"
      },
      "outputs": [],
      "source": [
        "def get_category_from_path(file_path):\n",
        "    # Extract the folder name from the path to use it as the category\n",
        "    folder_name = os.path.basename(os.path.dirname(file_path))\n",
        "    return folder_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TcUyQYb0M6b0"
      },
      "outputs": [],
      "source": [
        "# Create or load the persistent ChromaDB client\n",
        "db = PersistentClient(path=\"./storage/chroma\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agW2G0iajz84",
        "outputId": "5d851a08-a024-4947-af4f-f0775f59c419"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Chitt\\Downloads\\LLAMA2_code\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Chitt\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        }
      ],
      "source": [
        "# Load the Sentence Transformer model for disease\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_cxgCqF8NB7S"
      },
      "outputs": [],
      "source": [
        "def create_collection(name):\n",
        "    # Initialize ChromaDB\n",
        "    base_dir = 'data/data/' + name\n",
        "    collection = db.get_or_create_collection(name)\n",
        "\n",
        "    for root, dirs, files in os.walk(base_dir):\n",
        "        for file in files:\n",
        "            if file.endswith(\".pdf\"):\n",
        "              file_path = os.path.join(root, file)\n",
        "\n",
        "              # Extract text from the PDF\n",
        "              text = extract_text_from_pdf(file_path)\n",
        "\n",
        "              # Assign category based on folder structure\n",
        "              category = get_category_from_path(file_path)\n",
        "\n",
        "              # Generate embeddings for the document\n",
        "              document_embedding = model.encode(text).tolist()\n",
        "\n",
        "              # Store document with metadata in ChromaDB\n",
        "              collection.add(\n",
        "                  documents=[text],\n",
        "                  embeddings=[document_embedding],\n",
        "                  ids=[file_path],  # Use file path as a unique ID\n",
        "                  metadatas=[{'category': category, \"file_name\": file}]\n",
        "              )\n",
        "    return collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1BXF2IOvIdq",
        "outputId": "7d663604-f627-4cc1-ff7e-c4510acab7cd"
      },
      "outputs": [],
      "source": [
        "def delete_collection(collection_name):\n",
        "    try:\n",
        "        db.delete_collection(collection_name)\n",
        "        print(f\"Collection '{collection_name}' has been deleted successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while deleting the collection: {e}\")\n",
        "\n",
        "# delete_collection(\"diet_plan\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEk3tvPZMiCP",
        "outputId": "5d673ff0-684a-4cc7-dccd-6fa17797c2ed"
      },
      "outputs": [],
      "source": [
        "disease_collection = create_collection(\"disease\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdpzdTVMNu2A"
      },
      "outputs": [],
      "source": [
        "# diet_plan_collection = create_collection(\"diet_plan\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZclDqfKVMozF"
      },
      "outputs": [],
      "source": [
        "# Querying the collection can be added here as needed\n",
        "# For example, you can create a function to perform semantic searches\n",
        "def query_chroma_db(collection, query_text, n_results=5):\n",
        "    \"\"\"Query the ChromaDB collection with a semantic search.\"\"\"\n",
        "    query_embedding = model.encode(query_text).tolist()\n",
        "\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_embedding],\n",
        "        n_results=n_results\n",
        "    )\n",
        "    print(results)\n",
        "    # for document, metadata in zip(results['documents'][0], results['metadatas'][0]):\n",
        "    #     print(f\"Filename: {metadata['filename']}\\nContent: {document}\\n\")\n",
        "    return results['metadatas']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fodCadfOQQo",
        "outputId": "362eeafb-48c1-45fc-b821-8bf43350e48c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ids': [[]], 'embeddings': None, 'documents': [[]], 'uris': None, 'data': None, 'metadatas': [[]], 'distances': [[]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m query_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMy age is 66years, height is 5.7ft and weight is 120 pounds. I have vomiting and loss of appetite. what disease I might have?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m response \u001b[38;5;241m=\u001b[39m query_chroma_db(disease_collection, query_text, n_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m disease \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "\u001b[1;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# Example usage of querying the collection\n",
        "user_query = \"My age is 66years, height is 5.7ft and weight is 120 pounds. I have vomiting and loss of appetite. Suggest some diet plans.\"\n",
        "response = query_chroma_db(disease_collection, user_query, n_results=1)\n",
        "disease = response[0][0]['category']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz0Pnq8G_HuV",
        "outputId": "53d9c9f8-595f-4cf3-cd26-6d11aa851a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TytCqtck_CvX"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "You are a nutrition AI assistant and your task is to suggest only diet plans. Below are the rules you need to follow:\n",
        "- The input query will contain user disease.\n",
        "- Consider disease and suggest diet plans to user using the context provided.\n",
        "NO PREAMBLE.\n",
        "\"\"\"\n",
        "# - Your primary role is to suggest diet plans based on disease provided.\n",
        "# - Provide clear, accurate, and relevant information to users, maintaining a friendly and professional tone.\n",
        "# - Use context provided to find diet plans.\n",
        "# - The input query will contain 2 paragraphs. First is about disease and second is about user specific details.\n",
        "## Default format supportable by LLama2\n",
        "\n",
        "# You are a nutrition AI assistant and your task is to suggest only diet plans. Below are the rules you need to follow:\n",
        "# - The input query will contain 2 paragraphs. First paragraph tells you what disease user has and second paragraph says user age, height, weight and symptoms.\n",
        "# - Consider disease and user age, height, weight and suggest diet plans to user using the context provided.\n",
        "# - You need to understand the disease and user specific details to suggest appropriate diet plans.\n",
        "# NO PREAMBLE.\n",
        "query_wrapper_prompt = SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "8ba1bf44e5b14dd6a793b400b8be800b",
            "25ee81e0491442099b310668cd1fcaff",
            "09d876b096964149871f4834a6412bc2",
            "121d482637c246238d4478e62a19d310",
            "2ae5e5ce9604454aa8214a06b0a0c089",
            "26f59b493d2b4065be48bf182f5a5454",
            "698981b0f3f540bc8842f2b9c33ddd45",
            "a6f2799bb18f4af98ee4a1a9625eae5c",
            "fbc983e72b3343acbf15a60688b95026",
            "838ebc9e37df41e5b59da099fb715551",
            "c9a1ee127a6547f79a008ac422fd5e8c"
          ]
        },
        "id": "Z7Rb-hBx--Oz",
        "outputId": "d3049c5d-7bec-485b-c1c8-66802cf1e2c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# meta-llama/Meta-Llama-3.1-8B\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdo_sample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_wrapper_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_wrapper_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Llama-2-7b-chat-hf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Llama-2-7b-chat-hf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorch_dtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mload_in_8bit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Chitt\\Downloads\\LLAMA2_code\\.venv\\Lib\\site-packages\\llama_index\\llms\\huggingface\\base.py:237\u001b[0m, in \u001b[0;36mHuggingFaceLLM.__init__\u001b[1;34m(self, context_window, max_new_tokens, query_wrapper_prompt, tokenizer_name, model_name, model, tokenizer, device_map, stopping_ids, tokenizer_kwargs, tokenizer_outputs_to_remove, model_kwargs, generate_kwargs, is_chat_model, callback_manager, system_prompt, messages_to_prompt, completion_to_prompt, pydantic_program_mode, output_parser)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize params.\"\"\"\u001b[39;00m\n\u001b[0;32m    236\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m model_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m--> 237\u001b[0m model \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;66;03m# check context_window\u001b[39;00m\n\u001b[0;32m    242\u001b[0m config_dict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mto_dict()\n",
            "File \u001b[1;32mc:\\Users\\Chitt\\Downloads\\LLAMA2_code\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\Chitt\\Downloads\\LLAMA2_code\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3452\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3449\u001b[0m     hf_quantizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3452\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\n\u001b[0;32m   3454\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3455\u001b[0m     torch_dtype \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_torch_dtype(torch_dtype)\n\u001b[0;32m   3456\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_device_map(device_map)\n",
            "File \u001b[1;32mc:\\Users\\Chitt\\Downloads\\LLAMA2_code\\.venv\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_8bit.py:81\u001b[0m, in \u001b[0;36mBnb8BitHfQuantizer.validate_environment\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_bitsandbytes_multi_backend_available\n\u001b[0;32m     80\u001b[0m bnb_multibackend_is_enabled \u001b[38;5;241m=\u001b[39m is_bitsandbytes_multi_backend_available()\n\u001b[1;32m---> 81\u001b[0m \u001b[43mvalidate_bnb_backend_availability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_tf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_flax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m sure the weights are in PyTorch format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\Chitt\\Downloads\\LLAMA2_code\\.venv\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:558\u001b[0m, in \u001b[0;36mvalidate_bnb_backend_availability\u001b[1;34m(raise_exception)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bitsandbytes_multi_backend_available():\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _validate_bnb_multi_backend_availability(raise_exception)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_validate_bnb_cuda_backend_availability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_exception\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Chitt\\Downloads\\LLAMA2_code\\.venv\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:536\u001b[0m, in \u001b[0;36m_validate_bnb_cuda_backend_availability\u001b[1;34m(raise_exception)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_exception:\n\u001b[0;32m    535\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(log_msg)\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(log_msg)\n\u001b[0;32m    538\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(log_msg)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# meta-llama/Meta-Llama-3.1-8B\n",
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=256,\n",
        "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    device_map=\"auto\",\n",
        "    model_kwargs={\"torch_dtype\": torch.float16 , \"load_in_8bit\":True}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQMB0w6Y-6E6",
        "outputId": "eb535eca-d51b-4a98-fe41-b6cca0f154a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-4defcc445203>:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQa6vui2-2vv"
      },
      "outputs": [],
      "source": [
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "Settings.node_parser = SentenceSplitter(chunk_size=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fr3zQh7wEAi",
        "outputId": "8e3f8114-761d-42e3-88b4-9173cb36eb8c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 17 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 41 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 44 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 51 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 53 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 60 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 159 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 180 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 182 0 (offset 0)\n"
          ]
        }
      ],
      "source": [
        "# Load PDF documents from the diet_plan directory\n",
        "diet_plan_documents = SimpleDirectoryReader(\"./data/data/diet_plan\", recursive=True).load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "92b750b2a74e4e66908887fb04cb3ed6",
            "17d42a1f54e847d8aa30960700ec96a7",
            "e349d9d080da46fab6a25ed55df0d550",
            "3c56fe9eece948a6b419c82424b78ddc",
            "14ad7e571d7a4515a799f45f39ad760e",
            "9202bf86ddc94891a4b4fea16cf82ee3",
            "9e39cacc03b74a8fba693225a1ed814f",
            "d5421950ea3f4a2abf2934730d08a41f",
            "7733b2922d0240f2b9cb90ce4b18669e",
            "b3b5f356be4a4a5598e216104259bfec",
            "9f6a1eee872441fc91698c15008acf45",
            "cee42aa31a854445ae46ad13b4ca9cfb",
            "6f6a3c5e514a45738b627284226eecd3",
            "42389f81e47b42bda3315b186fa1080f",
            "425986d8e2e348ebbb0c75fa88b7b6e2",
            "28c1f308a1034af6bf8619f366622790",
            "697cf00c5f814fb1b8765bc6a183fd8f",
            "e253e0e51f4f4ee7a7b750e4f9179422",
            "4eaed0e033104a1ea8dbcc5182736500",
            "faa1aa4972b94c898642c02054cecc05",
            "5c9f3874d817420399f77c396b3b2534",
            "d932d0346f7b4f2fafc2d0dea7796801"
          ]
        },
        "id": "Cs7hCPWCmE4b",
        "outputId": "318f64af-9fe8-47bb-fad3-29a8c7b62cab"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92b750b2a74e4e66908887fb04cb3ed6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Parsing nodes:   0%|          | 0/467 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cee42aa31a854445ae46ad13b4ca9cfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating embeddings:   0%|          | 0/727 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# \"\"\" SAVE TO LOCAL\"\"\"\n",
        "diet_plan_collection = db.get_or_create_collection(\"diet_plan\")\n",
        "vector_store = ChromaVectorStore(chroma_collection=diet_plan_collection)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "diet_plan_index = VectorStoreIndex.from_documents(diet_plan_documents, storage_context=storage_context, show_progress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmgNnE9gmCc5"
      },
      "outputs": [],
      "source": [
        "# disease_documents = SimpleDirectoryReader(\"data/disease\").load_data()\n",
        "# # \"\"\" SAVE TO LOCAL\"\"\"\n",
        "# db = chromadb.PersistentClient(path=\"./storage/chroma\")\n",
        "# chroma_collection = db.get_or_create_collection(\"disease\")\n",
        "# vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "# disease_index = VectorStoreIndex.from_documents(disease_documents, storage_context=storage_context, show_progress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31bfQSvFmGoD"
      },
      "outputs": [],
      "source": [
        "# # fetch documents and index from storage\n",
        "# db = chromadb.PersistentClient(path=\"./storage/chroma\")\n",
        "# chroma_collection = db.get_or_create_collection(\"diseases\")\n",
        "# chroma_vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "# chroma_index = VectorStoreIndex.from_vector_store(vector_store=chroma_vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAGR8gObmIo3",
        "outputId": "123a6c06-66ed-4de2-b074-8b3884c34ffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available collections: [Collection(id=0b2deaec-bc7d-439b-9def-281fd954a280, name=diet_plan), Collection(id=f0053aab-a486-457c-b237-cce3b5e5d7e1, name=disease)]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Available collections: {db.list_collections()}\")    # <- this returns the collection that I want to get"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7LQEV80mJF4"
      },
      "outputs": [],
      "source": [
        "query_engine=diet_plan_index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnJwZVUXmKs-",
        "outputId": "1b585195-883a-4829-f1c1-691787da1eb8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Response(response=\"Thank you for reaching out! I'm here to help you with any questions or concerns you may have about diabetes. Based on the context information provided, it seems that you are looking for information on how to manage diabetes effectively.\\n\\nFirstly, it's important to understand that diabetes is a chronic health condition that requires ongoing management to prevent complications. The two primary types of diabetes are Type 1 and Type 2, and each has different causes and management strategies.\\n\\nType 1 diabetes is an autoimmune condition that destroys insulin-producing beta cells in the pancreas, requiring individuals to rely on insulin injections or an insulin pump for survival. Effective management of Type 1 diabetes involves monitoring blood sugar levels regularly, adjusting insulin doses accordingly, and maintaining a healthy diet and exercise routine.\\n\\nType 2 diabetes, on the other hand, is associated with insulin resistance and lifestyle factors such as obesity and physical inactivity. This type of diabetes can often be managed through lifestyle modifications such as a healthy di\", source_nodes=[NodeWithScore(node=TextNode(id_='3b2052cd-c838-4947-95c6-29a17f5473cc', embedding=None, metadata={'page_label': '1', 'file_name': 'PII0002822394902119.pdf', 'file_path': '/content/data/data/diet_plan/Diabetes/PII0002822394902119.pdf', 'file_type': 'application/pdf', 'file_size': 416805, 'creation_date': '2024-10-21', 'last_modified_date': '2024-10-14'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3b8cc231-f09c-4d8f-a6e8-e85f8e3d71d6', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '1', 'file_name': 'PII0002822394902119.pdf', 'file_path': '/content/data/data/diet_plan/Diabetes/PII0002822394902119.pdf', 'file_type': 'application/pdf', 'file_size': 416805, 'creation_date': '2024-10-21', 'last_modified_date': '2024-10-14'}, hash='91f57c1e2a329c41f572f1c064078b55ab21c710eafb61933b5e369c448825ec'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='6882c8a1-f85c-4a3d-912b-5e7fd29ce39d', node_type=<ObjectType.TEXT: '1'>, metadata={'page_label': '1', 'file_name': 'PII0002822394902119.pdf', 'file_path': '/content/data/data/diet_plan/Diabetes/PII0002822394902119.pdf', 'file_type': 'application/pdf', 'file_size': 416805, 'creation_date': '2024-10-21', 'last_modified_date': '2024-10-14'}, hash='2a2c4ecd26cf0997b220ef6383847c37b7859b96df61e24d93b2fcd006389b2a')}, text='It is recommended that\\nindividuals using insulin therapy eat at consistent times synchro-\\nnized with the time-action of the insulin preparation used. Fur-\\nther, individuals need to monitor blood glucose levels and adjust\\ninsulin doses for the amount of food usually eaten. Intensified\\ninsulin therapy, such as multiple daily injections or use of an\\ninsulin pump, allows considerable flexibility in when and what\\nindividuals eat. With intensified therapy, insulin regimens should\\nbe integrated with lifestyle and adjusted for deviations from usual\\neating and exercise habits.\\nNUTRITION THERAPY AND TYPE II DIABETES\\nThe emphasis for medical nutrition therapy in type II diabetes\\nshould be placed on achieving glucose, lipid, and blood pressure\\ngoals. Weight loss and hypocaloric diets usually improve short-\\nterm glycemic levels and have the potential to increase long-term\\nmetabolic control. However, traditional dietary strategies, and\\neven very-low-calorie diets, have usually not been effective in\\nachieving long-term weight loss; therefore, emphasis should be\\nplaced instead on glucose and lipid goals. Although weight loss is\\ndesirable, and some individuals are able to lose and maintain\\nweight loss, several additional strategies can be implemented to\\nimprove metabolic control. There is no one proven strategy or\\nmethod that can be uniformly recommended.\\nAn initial strategy is improvement in food choices, as illustrated\\nby Dietary Guidelines for Americans and the Food Guide\\nPyramid. A nutritionally adequate meal plan with a reduction of\\ntotal fat, especially saturated fats, can be employed. Spacing\\nmeals (spreading nutrient intake throughout the day) is another\\nstrategy that can be adopted. Mild to moderate weight loss (5 to10\\nkg [10 to 20 lb]) has been shown to improve diabetes control, even\\nif desirable body weight is not achieved. Weight loss is best\\nattempted by a moderate decrease in energy intake and an\\nincrease in caloric expenditure. Moderate caloric restriction (250-\\n500 kcal less than average daily intake) is recommended.\\nRegular exercise and learning new behaviors and attitudes can\\nhelp facilitate long-term lifestyle changes. Monitoring blood glu-\\ncose levels, glycated hemoglobin, lipids, and blood pressure is\\n504 / MAY 1994 VOLUME 94 NUMBER 5', mimetype='text/plain', start_char_idx=4063, end_char_idx=6341, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.519719005938438), NodeWithScore(node=TextNode(id_='8e39a6fe-bdb1-48dd-bebc-a786d7bbbbea', embedding=None, metadata={'page_label': '37', 'file_name': 'Nutrition_Resource_Guide.pdf', 'file_path': '/content/data/data/diet_plan/Diabetes/Nutrition_Resource_Guide.pdf', 'file_type': 'application/pdf', 'file_size': 2495818, 'creation_date': '2024-10-21', 'last_modified_date': '2024-10-14'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c512b2fe-b3f1-4581-ade6-8fa8c287313c', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '37', 'file_name': 'Nutrition_Resource_Guide.pdf', 'file_path': '/content/data/data/diet_plan/Diabetes/Nutrition_Resource_Guide.pdf', 'file_type': 'application/pdf', 'file_size': 2495818, 'creation_date': '2024-10-21', 'last_modified_date': '2024-10-14'}, hash='631fe22d08bacad149c4bbdabd1645afcb556073c7ca196d03f2ec65090e34f8')}, text='Basic Nutrition and Doctor Prescribed Diets  \\nPage 37 of 103 \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n.   \\n HEALTHY EATING \\nWITH DIABETES   \\nWhat is diabetes ? \\nDiabetes is a disease in which the body does not produce or properly  \\nuse insulin, which is a hormone that is needed to convert sugar, star ches \\nand other food into energy.  When someone has diabetes his or her body has \\ndifficulty controlling blood sugar levels.  \\n \\nEating Healthy with Diabetes  \\nHaving a good healthy diet is one of the most important ways to help \\ncontrol blood sugar, (along with m edication and exercise ). A go od diet and \\nexercise go hand in  hand to improve your blood sugar levels.  Good control \\nof your blood sugar helps protect your health. Healthy foods for eating with \\ndiabetes  are divided into th ree main groups: carbohydrates, pro teins, and \\nfats.  While each group is important for good health, carbohydrate is what \\nhas the greatest impact on blood sugar control.  By following a meal plan a \\npersons intake of carbohydrate as well as calories should be consistent and \\nconstant.  \\n \\n \\n Imp ortant Guidelines  \\n\\uf0fc Eat on time.  Meals should be no more than 4 -5 hours apart \\nand should be eaten at the same time each day.  \\n\\uf0fc Measure your foods to learn portion sizes.  Eat all the food \\nallowed, dont eat more or less. Snacking between meals \\nshould be a pla nned part of your meal plan.  Fruit is not a free \\nfood.  \\n\\uf0fc Limit sugars and sweets.  Avoid using a lot of diabetic or f at \\nfree foods  as they can be expensive and full of sugar and \\n(empty) calories.  \\n\\uf0fc Reduce saturated fat intake.  \\n\\uf0fc Increase fiber in diet by incl uding more whole grain breads \\nand cereals and fruits and vegetables.  \\n\\uf0fc If you are overweight, losing weight can help control your \\nblood sugar.  \\n\\uf0fc Read the food labels.  The total amount of carbohydrate on \\nthe nutrition label tells you how much carbohydrate (sug ar) is \\nin 1 serving.  \\n\\uf0fc Exercise plays an important part in controlling blood sugar.  \\nRegular exercise also helps you to feel better physically and \\nemotionally.', mimetype='text/plain', start_char_idx=2, end_char_idx=2095, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5023777806803053)], metadata={'3b2052cd-c838-4947-95c6-29a17f5473cc': {'page_label': '1', 'file_name': 'PII0002822394902119.pdf', 'file_path': '/content/data/data/diet_plan/Diabetes/PII0002822394902119.pdf', 'file_type': 'application/pdf', 'file_size': 416805, 'creation_date': '2024-10-21', 'last_modified_date': '2024-10-14'}, '8e39a6fe-bdb1-48dd-bebc-a786d7bbbbea': {'page_label': '37', 'file_name': 'Nutrition_Resource_Guide.pdf', 'file_path': '/content/data/data/diet_plan/Diabetes/Nutrition_Resource_Guide.pdf', 'file_type': 'application/pdf', 'file_size': 2495818, 'creation_date': '2024-10-21', 'last_modified_date': '2024-10-14'}})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_query = \"{disease}\".format(disease=disease_description[disease]) #  \\n {user_query} , user_query=user_query\n",
        "response=query_engine.query(input_query)\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yhXq4EVmMIM"
      },
      "outputs": [],
      "source": [
        "response=query_engine.query(\"What is your name?\")\n",
        "response.response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT8zVz6ZmOon"
      },
      "outputs": [],
      "source": [
        "response=query_engine.query(\"How many times a week someone can eat fish?\")\n",
        "response.response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LFomHhymRKb"
      },
      "outputs": [],
      "source": [
        "response=query_engine.query(\"How are you trained?\")\n",
        "response.response"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09d876b096964149871f4834a6412bc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6f2799bb18f4af98ee4a1a9625eae5c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbc983e72b3343acbf15a60688b95026",
            "value": 2
          }
        },
        "121d482637c246238d4478e62a19d310": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_838ebc9e37df41e5b59da099fb715551",
            "placeholder": "",
            "style": "IPY_MODEL_c9a1ee127a6547f79a008ac422fd5e8c",
            "value": "2/2[01:11&lt;00:00,32.75s/it]"
          }
        },
        "14ad7e571d7a4515a799f45f39ad760e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17d42a1f54e847d8aa30960700ec96a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9202bf86ddc94891a4b4fea16cf82ee3",
            "placeholder": "",
            "style": "IPY_MODEL_9e39cacc03b74a8fba693225a1ed814f",
            "value": "Parsingnodes:100%"
          }
        },
        "25ee81e0491442099b310668cd1fcaff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26f59b493d2b4065be48bf182f5a5454",
            "placeholder": "",
            "style": "IPY_MODEL_698981b0f3f540bc8842f2b9c33ddd45",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "26f59b493d2b4065be48bf182f5a5454": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28c1f308a1034af6bf8619f366622790": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ae5e5ce9604454aa8214a06b0a0c089": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c56fe9eece948a6b419c82424b78ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3b5f356be4a4a5598e216104259bfec",
            "placeholder": "",
            "style": "IPY_MODEL_9f6a1eee872441fc91698c15008acf45",
            "value": "467/467[00:01&lt;00:00,389.19it/s]"
          }
        },
        "42389f81e47b42bda3315b186fa1080f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eaed0e033104a1ea8dbcc5182736500",
            "max": 727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_faa1aa4972b94c898642c02054cecc05",
            "value": 727
          }
        },
        "425986d8e2e348ebbb0c75fa88b7b6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c9f3874d817420399f77c396b3b2534",
            "placeholder": "",
            "style": "IPY_MODEL_d932d0346f7b4f2fafc2d0dea7796801",
            "value": "727/727[00:20&lt;00:00,33.95it/s]"
          }
        },
        "4eaed0e033104a1ea8dbcc5182736500": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c9f3874d817420399f77c396b3b2534": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "697cf00c5f814fb1b8765bc6a183fd8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "698981b0f3f540bc8842f2b9c33ddd45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f6a3c5e514a45738b627284226eecd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_697cf00c5f814fb1b8765bc6a183fd8f",
            "placeholder": "",
            "style": "IPY_MODEL_e253e0e51f4f4ee7a7b750e4f9179422",
            "value": "Generatingembeddings:100%"
          }
        },
        "7733b2922d0240f2b9cb90ce4b18669e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "838ebc9e37df41e5b59da099fb715551": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ba1bf44e5b14dd6a793b400b8be800b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25ee81e0491442099b310668cd1fcaff",
              "IPY_MODEL_09d876b096964149871f4834a6412bc2",
              "IPY_MODEL_121d482637c246238d4478e62a19d310"
            ],
            "layout": "IPY_MODEL_2ae5e5ce9604454aa8214a06b0a0c089"
          }
        },
        "9202bf86ddc94891a4b4fea16cf82ee3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92b750b2a74e4e66908887fb04cb3ed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17d42a1f54e847d8aa30960700ec96a7",
              "IPY_MODEL_e349d9d080da46fab6a25ed55df0d550",
              "IPY_MODEL_3c56fe9eece948a6b419c82424b78ddc"
            ],
            "layout": "IPY_MODEL_14ad7e571d7a4515a799f45f39ad760e"
          }
        },
        "9e39cacc03b74a8fba693225a1ed814f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f6a1eee872441fc91698c15008acf45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6f2799bb18f4af98ee4a1a9625eae5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3b5f356be4a4a5598e216104259bfec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9a1ee127a6547f79a008ac422fd5e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cee42aa31a854445ae46ad13b4ca9cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f6a3c5e514a45738b627284226eecd3",
              "IPY_MODEL_42389f81e47b42bda3315b186fa1080f",
              "IPY_MODEL_425986d8e2e348ebbb0c75fa88b7b6e2"
            ],
            "layout": "IPY_MODEL_28c1f308a1034af6bf8619f366622790"
          }
        },
        "d5421950ea3f4a2abf2934730d08a41f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d932d0346f7b4f2fafc2d0dea7796801": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e253e0e51f4f4ee7a7b750e4f9179422": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e349d9d080da46fab6a25ed55df0d550": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5421950ea3f4a2abf2934730d08a41f",
            "max": 467,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7733b2922d0240f2b9cb90ce4b18669e",
            "value": 467
          }
        },
        "faa1aa4972b94c898642c02054cecc05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbc983e72b3343acbf15a60688b95026": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
